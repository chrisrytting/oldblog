---
layout: post
title:  "Mental Play"
date:   2020-12-31 10:31:53 -0600
categories: jekyll update
---
Noam Chomsky famously works on technical problems in his head during conversations with people. This is non-trivial in at least two major ways. One must be able to work on technical problems in one's head, and one must be able to do it as a parallel process to another challenging piece of cognition, which is to converse well. 

So when I came across this claim, I did what I always do when I hear about exceptional achievers: assume I could replicate their achievement. The problem is that I have trouble with both aspects of what he does, making progress on problems in my head and multi-tasking. This article will focus on the former endeavor, and if I ever get okay at it, I'll attack the latter.

There are several things that make head-progress hard:

First, you have so many things that you could think about that it's unlikely, without conscious regulation, that you will think about something coherently enough for long enough to realize something that you didn't realize before. This is exacerbated in the age of television and the internet, since both of these media are ones of abundant novelty, which coupled with our taste for novelty constitutes one of the reasons they are so popular. Abundance of entertaining novelty, though, changes our brains so that they are less tolerant of the tedium required for progress on thought (see _Amusing Ourselves to Death_ by Neil Postman, _Deep Work_ by Cal Newport, or _The Shallows_ by Nicholas Carr). Thus, this problem is likely worse in the 21st century than in others. 

The second impediment is a result of the first one: because of this drift towards novelty, we are unaccustomed to seeing problems solved from start to finish. Our attentional bandwidth has attenuated, and a considerable amount is needed to absorb a problem's context and definition let alone its proposed solution. We are used to giving attention to each new stimulus, be it external or internal, whose worth is based on how entertaining it is or how good it feels. This associational thought supplants the sequential thought needed to follow the arc of an argument from its context to its conclusions. Social media's units grow shorter, more atomic, and self-contained, and each earns presentation through its popularity, not its relevance. This is imposed channel-surfing, with brevity and randomness guaranteed. If we don't even consume sequential thought, the odds that we are producing it are low, and sequential thought is needed for making progress on problems.

The first problem, that of having too many things to think about, can be solved by strategically narrowing your thoughts. To solve a technical problem, you need a question, a solution, and an argument. As you make choices about each, the space of thought gets progressively more constrained until you are no longer overwhelmed by all possible paths of thought, but are considering a small set of them according to your new boundaries. 

The main thing motivating a technical problem is a question. Out of an infinity of questions, a small subset is chosen. Questions have different levels of objectivity/subjectivity, and they come in different languages. 

There are the questions expressed in natural language, both objective and subjective. An example of the former might be "Will a price of $5 yield a higher profit, or will a price of $10 yield a higher profit?", and an example of the latter might be "What makes human beings happy?". The objectivity or subjectivity of a problem depends on the concreteness of the definitions involved. Profit, as measured in revenue minus cost for all units produced and sold, is a much clearer, more objective metric than happiness of humans, because it is easy to understand the definition and anyone who measures profit as calculated above will agree. Happiness is subjective and difficult to quantify even for oneself, let alone for other people. 

Then there are problems that can be phrased formally in the language of mathematics: Solve for $x$ given $$(x/2) - 17=4$$. This question is perhaps even more objective than the profit question obtained above. While anyone measuring the outcome of production and exchange for a firm can calculate profits, they can't run counterfactual realities where everything was equal but the price. There are ways to simulate this process, as with randomized control trials, but they are imperfect. While it's clear they are better than guessing or just changing the price and observing the change in profit given an entirely different state of the world, it's also clear that they are not as good as what difference one would observe if going back in time and changing the sole detail of price; the magnitude of the difference is unclear.

Once you have chosen just one question, you have reduced the possible space of thought by an enormous amount, because you've rejected all paths starting with any other question, and you now have infinitely less options even while still having infinitely many options. This is true in the sense that Georg Cantor demonstrated different levels of infinity, even though to human intuition the infinity of real numbers contained between 0 and 1 isn't really discernible from the infinity of integers from negative infinity to infinity. 

Once you've settled on a question, you must come up with a feasible answer that makes sense. With some questions, you come up with a hypothesis about what the answer is, and then you test that hypothesis, as with questions asked by the scientific method. With other questions, there are ways to arrive at the answer without ever having prognosticated about what it might be, as with solving a system of equations where a variable is a quantity that must be algebraically solved. 

So you choose whether you want to design a method to solve your problem or come up with a hypothesis to test. 

Designing a method is hard to generalize. Algorithms, in general, are steps of computation that one undergoes sequentially to arrive eventually at an answer to the question, as with Euler's method or solving a system of equations. Algorithms are judged by how quickly and how surely they will get you to an answer. Designed methods can usually be construed as algorithms of some sort, whether the algorithm can be expressed in a computer program, a list of instructions expressed in English, or a sequence of calculations. One can think of these areas as a venn diagram, with plenty of overlap and plenty of difference between the categories.

On the other hand, we might lack an algorithm, as with traditional science, and we might construct a hypothetical solution to the question to test against the real world in some way. Depending on the circumstances, you might refer to this solution as a hypothesis, a model, or a theory. My impression is that the main degree of freedom between these concepts is the concreteness/generality of the solution. A theory of evolution might postulate that there is such a thing as evolution, which might be treated, under the label of theory, as a black box that does something. A model of evolution might postulate the specific way in which evolution performs its function and specify how DNA mutates and results in the construction of living things, which answers both what is done and how it is done. 

After coming up with a solution, we test against the real world to see whether it is not just feasible, but convincing. Thus, we might construct a hypothesis that exercise doesn't make a difference for people's happiness (call this the null-hypothesis) as defined by a survey a person takes. When we see enough evidence that a person is happier enough often enough after a run that it's infeasible to believe in the null-hypothesis, we reject it. This is a different way of saying we accept the alternative to the null-hypothesis and reason that exercise must make a difference for people's happiness. The number and extremity of observations both contribute to the confidence and credibility of this conclusion.

In working on technical problems in one's head, then, one must have clear the question that they are trying to answer, the method they are using to generate/propose a solution to that problem, and give evidence as to why it's a compelling or at least feasible solution to a problem. Not only is this a requirement for solving a problem, but a useful algorithm to follow when trying to solve the meta-question of what problem to work on. 

Then there is the problem of becoming comfortable with problem-thinking in your head. If a lack of practice is what got problem-solving out of our head in the first place, then it stands to reason that an abundance of practice might get it back in. Whether you prefer to think of this phenomenon through platitudes like "Use it or lose it" or through the technical details of myelin sheaths thickening around oft-used neurons and dendrites, an established finding of neuroscience and the lived experience of human beings is that the more you do something, the better your brain gets at doing it. This coincides with your brain doing more of it. Skill and tendency go hand in hand. It might be taxing in practice to follow the trajectory below, but it's my initially commonsense and progressively more enticing idea of how to get so good at in-head problem-solving that it feels natural, fun, and effective.

Depending on who you are, there are probably better and worse ways to get things into working memory. You might get something into working memory by visualizing it, by articulating it in your own voice or in writing, or by reciting it in your head. You can proceed through the essentials of a problem in these media. First, conceive a problem. Then, brainstorm what a solution might look like, according to similar problems you have seen solved before. Third, consider either an algorithm to solve it or how to test a hypothesis. With either of these approaches, it's useful to strategize about what should be done both abstractly and concretely, and planning and carrying out steps are both good ways to get a better grasp on the problem. If you know of other attempts to solve the problem, then you can compare your solution or your ideas for how to solve it to those of the other attempt, and evaluate the strengths and weaknesses of each attempt. 

At this point, you will have made at least some progress on the problem because you will understand part of what was and was not intuitive about the problem and your approach. Those differences help you determine the way you do and don't think and the way other people do and don't think along with  with the way problems either do or don't get solved. This can feel like a conversation with oneself, as if one were having a conversation with another person. Depending on who you are, this can be more or less generative than stewing over a problem in your own head, and can be copied or ignored accordingly.

Whether this conversation happens with yourself or with another person, it will probably include language, a set of symbols that are supposed to represent concepts (although this is often done imperfectly). Consider again, for example, the words "theory" and "model". These are different words, but have lots of overlap, which probably means that we experience some cognitive dissonance at the total difference in symbol and the incomplete difference in concept. This might result in an inefficiency in thinking, where every appearance of the word has us asking, "Now what is a model again and how is that different from a theory?" 

I have heard from multiple famous scientists that this inefficiency is something that goes away at a certain point for them. They include Albert Einstein 
>_"The words or the language, as they are written or spoken, do not seem to play any role in my mechanism of thought. The psychical entities which seem to serve as elements in thought are certain signs and more or less clear images which can be 'voluntarily' reproduced and combined... The above-mentioned elements are, in my case, of visual and some of muscular type. Conventional words or other signs have to be sought for laboriously only in a secondary stage, when the mentioned associative play is sufficiently established and can be reproduced at will."_

and Michael Nielsen 

>_"Typically, my mathematical work begins with paper-and-pen and messing about, often in a rather_ ad hoc _way. But over time if I really get into something my thinking starts to change. I gradually internalize the mathematical objects I’m dealing with. It becomes easier and easier to conduct (most of) my work in my head. I will go on long walks, and simply think intensively about the objects of concern. Those are no longer symbolic or verbal or visual in the conventional way, though they have some secondary aspects of this nature. Rather, the sense is somehow of working directly with the objects of concern, without any direct symbolic or verbal or visual referents."_

This reads basically as the notion that as one becomes more and more familiar with the aspects of a problem, one internalizes them in a way that obviates the need for language, and it becomes more clear how one can make progress on technical problems in one's head.

Our culture is not built for solving problems in one's head, much less working on those problems while having cognitively demanding conversations with other people, which themselves require a lot of brainpower. While I'm not entirely convinced that doing both simultaneously is a great approach (even if you're Noam Chomsky, aren't you sort of assuming you won't have to struggle to understand anything of what your partner in conversation is saying?), solving problems in-head is a great way to spend one's time. The practice of identifying the main components of a worthwhile problem and practicing this unnatural skill will at least get you much more respect from intelligent people, more money from rich people, and maybe, if you're lucky, even genuine progress on a technical problem.
